# Note
```
guid: D=FMwH>U./
notetype: Basic-d7a3e-4ce08
```

### Tags
```
01_instantiation
repeat
```

## Front
Name approaches for <b>Feature Engineering</b> of <b>numeric
data</b>.

## Back
<b>Raw data:</b> of numeric data can usually be consumed by machine
learning algorithms without any further adaptations <b>Basic
statistical measures:</b> like min, max, mean, median, var, count
or quantiles can be applied on raw data to generate new features
<b>Binarization:</b> reduces the feature to either one or zero.
This is used when the frequency is not important <b>Rounding:</b>
reduces the precision of the data points by converting the values
into numeric integers <b>Binning:</b> assigns data points to
discrete feature characteristics (bins). Fixed-width binning:
requires a pre-fixed range and assigns the datapoints accordingly.
<b>Adaptive binning:</b> requires a pre-fixed number of bins and
assigns the datapoints accordingly. <b>Monotonic
transformation:</b> like the log-transformation or the box-cox
transformation stabilize variance and makes the data more normal
distribution like
