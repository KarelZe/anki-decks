## Note
nid: 1607452837897
model: Basic-d7a3e
tags: 02_linear_classification
markdown: false

### Front
<p>Wie sieht der Gradient f√ºr die Multiclass Classification aus?
Vollziehen Sie die Berechnung nach.

### Back
<p>\[\begin{aligned}
\frac{\partial \operatorname{loss}_{i}}{\partial \boldsymbol{w}_{k}} &=\frac{\partial}{\partial \boldsymbol{w}_{k}}\left(\sum_{k=1}^{K} \boldsymbol{h}_{c_{i}, k} \boldsymbol{w}_{k}^{T} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)-\log \left(\sum_{j=1}^{K} \exp \left(\boldsymbol{w}_{j}^{T} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)\right)\right)\right) \\
&=\boldsymbol{h}_{c_{i}, k} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)-\frac{\partial}{\partial \boldsymbol{w}_{k}} \log \left(\sum_{j=1}^{K} \exp \left(\boldsymbol{w}_{j}^{T} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)\right)\right) \\
&=\boldsymbol{h}_{c_{i}, k} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)-\frac{1}{\sum_{j=1}^{K} \exp \left(\boldsymbol{w}_{j}^{T} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)\right)} \exp \left(\boldsymbol{w}_{k}^{T} \phi\left(\boldsymbol{x}_{i}\right)\right) \phi\left(\boldsymbol{x}_{i}\right) \\
&=\underbrace{\phi\left(\boldsymbol{x}_{i}\right)}_{\text {feature vector }} \underbrace{\left(\boldsymbol{h}_{c_{i}, k}-p\left(k \mid \boldsymbol{x}_{k}\right)\right)}_{\text {"soft-max error" }}
\end{aligned}\]
</p>
