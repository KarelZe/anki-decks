## Note
nid: 1656326102232
model: Basic-02d89
tags: 12_var_ml
markdown: false

### Front
Why autoencoders?

### Back
<ul>
  <li>Map high-dimensional data to two dimensions for
  visualization. Compression (i.e. reducing the file size; Requires
  VAE).
  <li>Learn abstract features in an unsupervised way so you can
  apply them to a supervised task.
  <li>Unlabled data can be much more plentiful than labeled data.
  <li>Learn a semantically meaningful representation where you can,
  e.g., interpolate between different images.
</ul>
