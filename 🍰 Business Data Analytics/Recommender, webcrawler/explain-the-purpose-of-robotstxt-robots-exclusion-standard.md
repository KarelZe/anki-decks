# Note
```
guid: f3Fmr[9-i@
notetype: Basic-02d89-e0e22
```

### Tags
```
bda::08_webcrawling_recommender
```

## Front
Explain the purpose of robots.txt (Robots Exclusion Standard).

## Back
<ul>
  <li>Restrict crawler access
  <li>Point crawlers to other URLs
  <li>Identify crawlers
  <li>Can be parsed and used automated programs easily
</ul>Example: # Welcome to my robots.txt User-agent: * Disallow: *
