# Note
```
guid: NKgz<v6Gd/
notetype: Basic-02d89-e0e22
```

### Tags
```
bda::10_text_mining
```

## Front
Explain the <b>Skip-Gram model</b>.

## Back
Fully connected feedforward neural network. <b>Training
objective:</b> learn embeddings that are good at predicting the
nearby words. Learning happens from a large corpus e. g.,
Wikipedia. During learning the errors of the model are added up.
<img src="paste-7b76b53eb595204d3613da1487b269a632caf0f4.jpg">
