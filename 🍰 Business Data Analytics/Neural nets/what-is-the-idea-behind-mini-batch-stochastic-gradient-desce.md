# Note
```
guid: s*%X@+/D)O
notetype: Basic-02d89-e0e22
```

### Tags
```
bda::06_trainining_tuning
```

## Front
What is the <b>idea</b> behind <b>mini-batch stochastic gradient
descent</b>?

## Back
Randomly shuffle training data prior to training.
Pick (mini) batches e. g., 32 / 1024 samples of data for training step.
