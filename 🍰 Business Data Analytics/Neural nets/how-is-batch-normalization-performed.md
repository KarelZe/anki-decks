# Note
```
guid: kA(7&qS-ZD
notetype: Basic-02d89-e0e22
```

### Tags
```
bda::06_trainining_tuning
```

## Front
How is <b>Batch Normalization</b> performed?

## Back
\(\hat{x}^{(i)}=\frac{x^{(i)}-\mu_{B}}{\sqrt{\sigma_{B}^{2}+\epsilon}}, z^{(i)}=\gamma \hat{x}^{(i)}+\beta\) (scaled and shifted version of layer input)
