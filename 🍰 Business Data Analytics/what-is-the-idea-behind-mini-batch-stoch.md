## Note
nid: 1653201773140
model: Basic-02d89
tags: 06_trainining_tuning_bda
markdown: false

### Front
What is the <b>idea</b> behind <b>mini-batch stochastic gradient
descent</b>?

### Back
Randomly shuffle training data prior to training.
Pick (mini) batches e. g., 32 / 1024 samples of data for training step.
