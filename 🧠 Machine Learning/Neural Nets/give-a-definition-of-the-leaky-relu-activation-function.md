# Note
```
guid: fLi*_J,)A&
notetype: Basic-d7a3e-4ce08
```

### Tags
```
checklater
ml::10_neural_networks
```

## Front
Give a definition of the <b>Leaky ReLU</b> activation function.

## Back
\(f(x)=\max (0.1 x, x)\)
<div><img src="paste-6e883ccb5efda948f8beac055d1221ac08ef10f4.jpg"></div>
