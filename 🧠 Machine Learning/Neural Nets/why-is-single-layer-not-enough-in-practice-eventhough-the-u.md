# Note
```
guid: G*UjFrki;?
notetype: Basic-d7a3e-4ce08
```

### Tags
```
ml::10_neural_networks
```

## Front
Why is single layer not enough in practice, eventhough the Universal Approximation Theorem states it?

## Back
The problem is, that you'd need an exponential number of units,
otherwise you overfit.
<div>
  With multiple layers you can have similiar effects and have a
  compact representation with less units.
</div>
