# Note
```
guid: Iz_Fpf)L30
notetype: Basic-d7a3e-4ce08
```

### Tags
```
checklater
ml::10_neural_networks
```

## Front
Give the formula for the Xavier initalization.

## Back
Default:
<div>
  \(\sigma_{\mathbf{W}}=\frac{1}{\sqrt{D_{\text {in }}}}\)
</div>
<div>
  Version that works with ReLU:
</div>
<div>
  \(\sigma_{\mathbf{W}}=\frac{2}{\sqrt{D_{\text {in }}}}\)
</div>
