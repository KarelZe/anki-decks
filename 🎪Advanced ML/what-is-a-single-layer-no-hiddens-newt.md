## Note
nid: 1620554558520
model: Basic-b122e
tags: 10_lecture
markdown: false

### Front
What is a single layer (no hiddens) newtwork with sigmoid
activation function?
<div><img src=
"paste-1b4d997ef44878da5fbfe4d009c258df38e979f7.jpg"></div>
<div>
  \[o_{k}(\mathrm{x})=\frac{1}{1+\exp \left(-z_{k}\right)}\]
</div>
<div>
  \[z_{k}=w_{k 0}+\sum_{j=1}^{J} x_{j} w_{k j}\]
</div>

### Back
Logistic Regression.
