## Note
nid: 1651475125615
model: Basic-02d89
tags: 02_basics_nn_dlcv
markdown: false

### Front
What are the <b>impact</b> of a wrongly chosen <b>learning rate</b>?

### Back
The learning rate \(\eta\) is a crucial hyperparameter.
If \(\eta\) is too large, the loss will fluctuate around the minimum or, in worst case, diverge.

If \(\eta\) is too small, it will converge slowly.

<img src="paste-f8efb69019261c8708e4da840b9f4a226e3f6d3c.jpg">
