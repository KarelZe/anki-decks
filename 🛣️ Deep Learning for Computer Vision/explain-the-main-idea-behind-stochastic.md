## Note
nid: 1651474288396
model: Basic-02d89
tags: 02_basics_nn_dlcv
markdown: false

### Front
Explain the main idea behind <b>Stochastic Gradient Descent /
mini-batch Gradient Descent</b>.

### Back
Approximate sum of loss with a mini-batch of examples (e. g. 3,2
64,...) Samples are randomly drawn from the entire set. <b>Pseudo
code:</b> <img src= 
"paste-975ceed90a5f1e60224410fb45a1b43bc5d69b51.jpg">
