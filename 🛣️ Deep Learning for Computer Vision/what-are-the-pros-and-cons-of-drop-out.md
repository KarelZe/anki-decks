## Note
nid: 1652108641319
model: Basic-02d89
tags: 03_nn_basics_dlcv
markdown: false

### Front
What are the <b>pros</b> and <b>cons</b> of <b>drop-out</b>?

### Back
<ul>
  <li>Effective against overfitting due to breaking-up situations
  where NN co-adapt to errors in previous layers
  <li>Activations of the hidden units become sparse, even when no
  regularizer is used
</ul>
