## Note
nid: 1615983539429
model: Basic-b122e
tags: 09_decision_trees
markdown: false

### Front
Wie ist die <b>Entropie nach Shannon</b> definiert?

### Back
Gegeben sei ein Alphabet \(Z=\left\{z_{1}, \ldots, z_{m}\right\}\).
<div>
  Es werden (zufällig) Elemente des Alphabets gezogen, diese Reihe
  heiße \(X\) . \(X\) wird auch Inputmenge genannt. Die
  Wahrscheinlichkeit für ein \(z_{i}\) in \(X\) sei \(p_{i}\).
  <div>
    Entropie der zufälligen Reihe \(X\)( mit \(i\) als Index in
    \(X\)):
  </div>
  <div>
    \[H=- \sum_{i=1}^{n} p_{i} \log _{2}p_{i}\]
  </div>
</div>
