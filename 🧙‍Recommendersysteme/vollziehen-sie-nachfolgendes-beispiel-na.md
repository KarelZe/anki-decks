## Note
nid: 1593352164668
model: Basic-b122e
tags: 09_decision_trees
markdown: false

### Front
Vollziehen Sie nachfolgendes <b>Beispiel</b> nach wie sich der
<b>Informationsgewinn für Attribute</b> mittels der Entropie
berechnen lässt.

### Back
<img src="paste-4754699c37e9d8ed24cd83ce1db0485fd0aef911.jpg"><div>Berechnung der <b>Informationsgewinne</b> für die Inputvariable "Outlook"</div><div><img src="paste-4c1e498de61e04cfcd59feadb27ccef861afdad2.jpg">
</div><div>
</div><div><b>Gewichtung der Informationsgewinne</b></div><div>Gewichtet wird mit den Wahrscheinlichkeiten, wie oft ein Ast erreicht wird z. B. 5 x Tennis spielen gehen von 14 x.</div><div><img src="paste-c63cd9a600bedff39471db5904084216c837773b.jpg">
</div><div>Berechnung der <b>Informationsgewinne</b> für die Inputvariable "Humidity"
</div><div><img src="paste-f9bcda508d4c3d98fd8b4420d469edbb5f4be586.jpg">
</div><div><b>Vergleich des Informationsgewinns aller Input-Attribute</b></div><div><img src="paste-aa24e1abdb16f5223517f8cc7d512362558073a9.jpg"></div><div><b>Erklärung der noch verbleibenden Attribute</b></div><div>Wir suchen in den Baumästen nach weiteren Attributen analog dem vorherigen Schritt.</div><div><img src="paste-ea2727d2af9422b26ed7ceaea00ca507e68177dd.jpg">
</div><div><img src="paste-e491d32cf6c91bcaa66f1df31ece77bf495e5775.jpg">
</div><div><b>Ergebnis</b></div><div><img src="paste-53621003c91a411af9b36dd458ef17038c5c8430.jpg"></div><div>
<div>
</div><div>
</div><div>
</div></div>
