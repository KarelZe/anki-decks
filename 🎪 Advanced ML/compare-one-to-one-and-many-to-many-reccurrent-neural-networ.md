# Note
```
guid: jfe/eG]yJK
notetype: Basic-d7a3e-4ce08
```

### Tags
```
12_lecture
```

## Front
Compare <b>one-to-one</b> and <b>many-to-many</b> <b>Reccurrent Neural Networks</b>.

## Back
<div>
<div><ul>
<li><strong>One-to-one</strong>: This is the classic feed forward neural network architecture, with one input and we expect one output.</li>
<li><strong>Many-to-many</strong>: This model is ideal for machine translation like the one we see on Google translate. The input could an English sentence which has variable length and the output will be the same sentence in a different language which also has variable length.</li>
</ul>
</div></div>
