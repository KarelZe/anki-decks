# Note
```
guid: IP+wM[D;(:
notetype: Basic-d7a3e-4ce08
```

### Tags
```
adv_ml::10_lecture
```

## Front
What is a single layer (no hiddens) newtwork with sigmoid
activation function?
<div><img src="paste-1b4d997ef44878da5fbfe4d009c258df38e979f7.jpg"></div>
<div>
  \[o_{k}(\mathrm{x})=\frac{1}{1+\exp \left(-z_{k}\right)}\]
</div>
<div>
  \[z_{k}=w_{k 0}+\sum_{j=1}^{J} x_{j} w_{k j}\]
</div>

## Back
Logistic Regression.
