## Note
nid: 1593352164668
model: Basic-b122e-20a86
tags: 09_decision_trees
markdown: false

### Front
Vollziehen Sie nachfolgendes <b>Beispiel</b> nach wie sich der
<b>Informationsgewinn für Attribute</b> mittels der Entropie
berechnen lässt.

### Back
<img src="paste-4754699c37e9d8ed24cd83ce1db0485fd0aef911.jpg">
<div>
  Berechnung der <b>Informationsgewinne</b> für die Inputvariable
  "Outlook"
</div>
<div><img src=
"paste-4c1e498de61e04cfcd59feadb27ccef861afdad2.jpg"></div>
<div>
  <b>Gewichtung der Informationsgewinne</b>
</div>
<div>
  Gewichtet wird mit den Wahrscheinlichkeiten, wie oft ein Ast
  erreicht wird z. B. 5 x Tennis spielen gehen von 14 x.
</div>
<div><img src=
"paste-c63cd9a600bedff39471db5904084216c837773b.jpg"></div>
<div>
  Berechnung der <b>Informationsgewinne</b> für die Inputvariable
  "Humidity"
</div>
<div><img src=
"paste-f9bcda508d4c3d98fd8b4420d469edbb5f4be586.jpg"></div>
<div>
  <b>Vergleich des Informationsgewinns aller Input-Attribute</b>
</div>
<div><img src=
"paste-aa24e1abdb16f5223517f8cc7d512362558073a9.jpg"></div>
<div>
  <b>Erklärung der noch verbleibenden Attribute</b>
</div>
<div>
  Wir suchen in den Baumästen nach weiteren Attributen analog dem
  vorherigen Schritt.
</div>
<div><img src=
"paste-ea2727d2af9422b26ed7ceaea00ca507e68177dd.jpg"></div>
<div><img src=
"paste-e491d32cf6c91bcaa66f1df31ece77bf495e5775.jpg"></div>
<div>
  <b>Ergebnis</b>
</div>
<div><img src=
"paste-53621003c91a411af9b36dd458ef17038c5c8430.jpg"></div>
